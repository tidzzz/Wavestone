{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c307ab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies charg√©es avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, hamming_loss\n",
    "import joblib\n",
    "\n",
    "# Configuration de l'affichage pour voir toutes les colonnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Librairies charg√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d4538ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chargement des donn√©es ---\n",
      "Matrice charg√©e : (5000, 324) (Utilisateurs x Permissions)\n",
      "Nombre d'utilisateurs : 5000\n",
      "Nombre de permissions : 324\n"
     ]
    }
   ],
   "source": [
    "# Chargement de la matrice et des catalogues\n",
    "print(\"--- Chargement des donn√©es ---\")\n",
    "X = load_npz('../out/user_permission_matrix_sparse.npz')\n",
    "users_df = pd.read_csv('../out/users_catalog.csv')\n",
    "perms_df = pd.read_csv('../out/perm_catalog.csv')\n",
    "apps_df = pd.read_csv('../out/app_catalog.csv')\n",
    "\n",
    "print(f\"Matrice charg√©e : {X.shape} (Utilisateurs x Permissions)\")\n",
    "print(f\"Nombre d'utilisateurs : {len(users_df)}\")\n",
    "print(f\"Nombre de permissions : {len(perms_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2a02368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permissions totales : 324\n",
      "Permissions conserv√©es pour la NMF : 324\n",
      "Permissions rejet√©es car trop communes (> 70.0%) : 0\n",
      "\n",
      "Lancement NMF sur 324 permissions...\n",
      "NMF termin√©e !\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration NMF ---\n",
    "\n",
    "# 1. Calcul de la fr√©quence\n",
    "X_binary = (X > 0).astype(int)\n",
    "user_count_per_perm = np.array(X_binary.sum(axis=0)).flatten()\n",
    "total_users = X.shape[0]\n",
    "freq_per_perm = user_count_per_perm / total_users\n",
    "\n",
    "# 2. D√©finition des bornes\n",
    "# On garde le seuil agressif pour virer le bruit (Slack, Zoom...)\n",
    "UPPER_LIMIT = 0.7  # Si + de 10% l'ont, on supprime...\n",
    "LOWER_LIMIT = 0.00  # On garde toutes les raret√©s\n",
    "\n",
    "\n",
    "# 3. Application du masque combin√©\n",
    "# R√®gle : (Est Rare) OU (Est Prot√©g√©)\n",
    "# Si c'est fr√©quent MAIS prot√©g√©, on garde !\n",
    "perms_to_keep_mask = ((freq_per_perm <= UPPER_LIMIT) & (freq_per_perm >= LOWER_LIMIT))\n",
    "\n",
    "# Stats pour v√©rifier\n",
    "n_total = len(perms_df)\n",
    "n_kept = np.sum(perms_to_keep_mask)\n",
    "\n",
    "print(f\"Permissions totales : {n_total}\")\n",
    "print(f\"Permissions conserv√©es pour la NMF : {n_kept}\")\n",
    "print(f\"Permissions rejet√©es car trop communes (> {UPPER_LIMIT*100}%) : {np.sum(freq_per_perm > UPPER_LIMIT)}\")\n",
    "\n",
    "\n",
    "\n",
    "# 5. Filtrage et Lancement NMF\n",
    "X_filtered = X[:, perms_to_keep_mask]\n",
    "perms_df_filtered = perms_df[perms_to_keep_mask].reset_index(drop=True)\n",
    "\n",
    "N_ROLES = 8\n",
    "print(f\"\\nLancement NMF sur {X_filtered.shape[1]} permissions...\")\n",
    "model_nmf = NMF(n_components=N_ROLES, init='nndsvd', random_state=42, max_iter=1000)\n",
    "W = model_nmf.fit_transform(X_filtered)\n",
    "\n",
    "# Normalisation\n",
    "W_norm = W / W.sum(axis=1, keepdims=True)\n",
    "W_norm = np.nan_to_num(W_norm)\n",
    "\n",
    "# Mise √† jour pour la suite\n",
    "print(\"NMF termin√©e !\")\n",
    "perms_df = perms_df_filtered \n",
    "H = model_nmf.components_ # Important pour l'affichage des noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "426dbc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANALYSE DES 8 R√îLES D√âCOUVERTS ---\n",
      "\n",
      "üîπ R√îLE ID 0\n",
      "   Dominante : GitHub Enterprise, CrowdStrike Falcon, ServiceNow ITSM, Confluence\n",
      "  manage_pipeline  GitHub Enterprise 3.738366\n",
      "            login CrowdStrike Falcon 3.727194\n",
      "      open_ticket    ServiceNow ITSM 3.720665\n",
      "manage_identities CrowdStrike Falcon 3.712883\n",
      "  manage_pipeline         Confluence 3.710987\n",
      "            login  GitHub Enterprise 3.710656\n",
      "    open_employee         Talentsoft 3.700795\n",
      "    read_messages         SharePoint 0.320545\n",
      "   create_channel         SharePoint 0.307191\n",
      "      manage_team               Zoom 0.287836\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 1\n",
      "   Dominante : Workday HCM, Talentsoft, Sage Paie, Oracle Financials Cloud\n",
      "            login             Workday HCM 3.251325\n",
      "    edit_employee              Talentsoft 3.239916\n",
      "            login               Sage Paie 3.239462\n",
      "    open_employee              Talentsoft 3.225341\n",
      "    edit_employee             Workday HCM 3.223494\n",
      "export_hr_reports              Talentsoft 3.211587\n",
      "  approve_payment Oracle Financials Cloud 3.211184\n",
      "    read_messages              SharePoint 0.324212\n",
      "   create_channel              SharePoint 0.303401\n",
      "            login              SharePoint 0.249261\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 2\n",
      "   Dominante : SAP S/4HANA Finance, Sage Paie, Power BI, ADP Payroll\n",
      "          login     SAP S/4HANA Finance 2.976672\n",
      " export_payroll               Sage Paie 2.966112\n",
      "share_dashboard                Power BI 2.963162\n",
      "  admin_payroll             ADP Payroll 2.952937\n",
      "       post_run               Sage Paie 2.945510\n",
      "approve_payment Oracle Financials Cloud 2.943305\n",
      "  read_messages              SharePoint 0.256576\n",
      "   post_message                    Zoom 0.255780\n",
      "          login                    Zoom 0.245807\n",
      "    manage_team                    Zoom 0.231012\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 3\n",
      "   Dominante : Databricks, CrowdStrike Falcon, Tableau Server, Zoom\n",
      "publish_report         Databricks 3.962018\n",
      "admin_security CrowdStrike Falcon 3.930927\n",
      "approve_report     Tableau Server 3.928493\n",
      "         login               Zoom 0.305726\n",
      "  post_message               Zoom 0.303074\n",
      "         login         SharePoint 0.300695\n",
      " read_messages               Zoom 0.291850\n",
      " read_messages         SharePoint 0.263927\n",
      "   manage_team               Zoom 0.262571\n",
      "create_channel               Zoom 0.256779\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 4\n",
      "   Dominante : Jira, Nessus, Okta, SharePoint\n",
      "          login       Jira 3.527752\n",
      "   create_alert     Nessus 3.522698\n",
      "   export_alert       Okta 3.520785\n",
      "  read_messages SharePoint 0.348230\n",
      " create_channel SharePoint 0.345292\n",
      "          login SharePoint 0.332948\n",
      "  read_messages       Zoom 0.288513\n",
      "   post_message       Zoom 0.248298\n",
      " approve_thread      Slack 0.235441\n",
      "approve_message       Zoom 0.225029\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 5\n",
      "   Dominante : CrowdStrike Falcon, SharePoint, Zoom\n",
      "quarantine_endpoint CrowdStrike Falcon 3.534145\n",
      "     admin_security CrowdStrike Falcon 3.523740\n",
      "      read_messages         SharePoint 0.408236\n",
      "     create_channel         SharePoint 0.345844\n",
      "       post_message               Zoom 0.299357\n",
      "              login               Zoom 0.281780\n",
      "     create_channel               Zoom 0.273016\n",
      "        manage_team               Zoom 0.229334\n",
      "              login         SharePoint 0.226763\n",
      "      read_messages               Zoom 0.216136\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 6\n",
      "   Dominante : ServiceNow ITSM, SharePoint, Zoom, Slack\n",
      "          login ServiceNow ITSM 2.542494\n",
      "     admin_itsm ServiceNow ITSM 2.517369\n",
      "    manage_team      SharePoint 2.422460\n",
      "          login      SharePoint 0.928498\n",
      " create_channel      SharePoint 0.257899\n",
      "   post_message            Zoom 0.231152\n",
      "    manage_team           Slack 0.198135\n",
      "          login Exchange Online 0.188456\n",
      "approve_message            Zoom 0.187443\n",
      " create_channel           Slack 0.185843\n",
      "--------------------------------------------------\n",
      "üîπ R√îLE ID 7\n",
      "   Dominante : SharePoint, Exchange Online, Outlook Web, Microsoft Teams\n",
      "   post_message      SharePoint 3.795060\n",
      " create_channel Exchange Online 0.054710\n",
      "approve_message     Outlook Web 0.040490\n",
      "   open_message Microsoft Teams 0.029199\n",
      " create_channel Microsoft Teams 0.028964\n",
      "  read_messages Exchange Online 0.028565\n",
      "    manage_team Microsoft Teams 0.022218\n",
      "      read_team           Slack 0.015369\n",
      " publish_report        Power BI 0.014324\n",
      " edit_warehouse        Power BI 0.014088\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- CELLULE D'ANALYSE DES R√îLES ---\n",
    "\n",
    "def inspecter_roles(H_matrix, n_top=10):\n",
    "    print(f\"--- ANALYSE DES {len(H_matrix)} R√îLES D√âCOUVERTS ---\\n\")\n",
    "    \n",
    "    for role_id, weights in enumerate(H_matrix):\n",
    "        # On trie les permissions par poids (les plus importantes d'abord)\n",
    "        top_indices = weights.argsort()[::-1][:n_top]\n",
    "        \n",
    "        # On r√©cup√®re les d√©tails\n",
    "        top_perms = perms_df.iloc[top_indices].copy()\n",
    "        top_perms['poids'] = weights[top_indices]\n",
    "        \n",
    "        # On ajoute le nom de l'appli pour y voir clair\n",
    "        # (Attention de bien avoir 'app_name' dans apps_df)\n",
    "        details = pd.merge(top_perms, apps_df, on='application_id', how='left')\n",
    "        \n",
    "        print(f\"üîπ R√îLE ID {role_id}\")\n",
    "        \n",
    "        # On affiche les 5-6 applis dominantes pour r√©sumer\n",
    "        apps_dominantes = details['app_name'].unique()[:4]\n",
    "        print(f\"   Dominante : {', '.join(apps_dominantes)}\")\n",
    "        \n",
    "        # On affiche le d√©tail des permissions\n",
    "        print(details[['perm_name', 'app_name', 'poids']].to_string(index=False, header=False))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Lancement de l'inspection\n",
    "inspecter_roles(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3cfc98d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Noms des r√¥les enregistr√©s ! Le mod√®le parlera maintenant fran√ßais.\n"
     ]
    }
   ],
   "source": [
    "# --- D√âFINITION HUMAINE DES R√îLES ---\n",
    "# Remplace les noms ci-dessous par ton analyse\n",
    "\n",
    "ROLE_NAMES = {\n",
    "    0: \"pack IT\",\n",
    "    1: \"RH / Finance\",\n",
    "    2: \"Finance\",\n",
    "    3: \"Data science\",\n",
    "    4: \"DEV OPS Secu\",\n",
    "    5: \"Cyber secu\",\n",
    "    6: \"ITSM\",\n",
    "    7: \"pack Collab\",\n",
    "   \n",
    "    \n",
    "}\n",
    "\n",
    "# --- MISE √Ä JOUR DE LA FONCTION D'AFFICHAGE ---\n",
    "# On √©crase l'ancienne fonction describe_role pour utiliser les nouveaux noms\n",
    "\n",
    "def describe_role(role_id):\n",
    "    # On cherche le nom dans ton dictionnaire\n",
    "    # Si on ne trouve pas, on met un nom par d√©faut\n",
    "    custom_name = ROLE_NAMES.get(role_id, f\"R√¥le {role_id} (Non nomm√©)\")\n",
    "    return f\"[{role_id}] {custom_name}\"\n",
    "\n",
    "print(\"‚úÖ Noms des r√¥les enregistr√©s ! Le mod√®le parlera maintenant fran√ßais.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b9718e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Distribution des R√¥les ---\n",
      "R√¥le 0 : 1326 utilisateurs (26.52%) ‚úÖ OK\n",
      "R√¥le 1 : 504 utilisateurs (10.08%) ‚úÖ OK\n",
      "R√¥le 2 : 559 utilisateurs (11.18%) ‚úÖ OK\n",
      "R√¥le 3 : 584 utilisateurs (11.68%) ‚úÖ OK\n",
      "R√¥le 4 : 1010 utilisateurs (20.20%) ‚úÖ OK\n",
      "R√¥le 5 : 1141 utilisateurs (22.82%) ‚úÖ OK\n",
      "R√¥le 6 : 1120 utilisateurs (22.40%) ‚úÖ OK\n",
      "R√¥le 7 : 427 utilisateurs (8.54%) ‚úÖ OK\n",
      "--- Statistiques Multi-R√¥les ---\n",
      "Avec un seuil de 15.0%, un utilisateur poss√®de en moyenne 1.33 r√¥les.\n",
      "Si ce chiffre est proche de 1, baisse le seuil. S'il est > 5, monte le seuil.\n"
     ]
    }
   ],
   "source": [
    "# --- D√âFINITION DU SEUIL ---\n",
    "# Si un utilisateur a plus de 10% de son \"ADN\" dans un r√¥le, on consid√®re qu'il l'a.\n",
    "THRESHOLD = 0.15\n",
    "\n",
    "# Y_binary est une matrice de 0 et 1.\n",
    "# Chaque ligne correspond √† un utilisateur, chaque colonne √† un r√¥le.\n",
    "# Exemple : [1, 0, 0, 1, ...] signifie \"Poss√®de le R√¥le 0 et le R√¥le 3\"\n",
    "Y_binary = (W_norm > THRESHOLD).astype(int)\n",
    "\n",
    "# Compte le nombre d'utilisateurs pour chaque r√¥le\n",
    "roles_counts = Y_binary.sum(axis=0)\n",
    "\n",
    "print(\"--- Distribution des R√¥les ---\")\n",
    "for i, count in enumerate(roles_counts):\n",
    "    percentage = (count / len(Y_binary)) * 100\n",
    "    status = \"‚ö†Ô∏è TROP RARE\" if percentage < 1 else \"‚úÖ OK\"\n",
    "    print(f\"R√¥le {i} : {count} utilisateurs ({percentage:.2f}%) {status}\")\n",
    "\n",
    "# V√©rification statistique\n",
    "avg_roles = np.mean(np.sum(Y_binary, axis=1))\n",
    "print(f\"--- Statistiques Multi-R√¥les ---\")\n",
    "print(f\"Avec un seuil de {THRESHOLD*100}%, un utilisateur poss√®de en moyenne {avg_roles:.2f} r√¥les.\")\n",
    "print(\"Si ce chiffre est proche de 1, baisse le seuil. S'il est > 5, monte le seuil.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "947eeb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pr√©paration et Entra√Ænement Supervis√© ---\n",
      "Mod√®le entra√Æn√© sur 4000 utilisateurs.\n",
      "Pr√©cision 'Subset' (Tout bon ou rien) : 63.40%\n",
      "--- Rapport de Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       262\n",
      "           1       1.00      1.00      1.00        97\n",
      "           2       1.00      0.96      0.98       113\n",
      "           3       1.00      0.92      0.96       105\n",
      "           4       0.72      0.99      0.83       187\n",
      "           5       0.83      0.99      0.90       241\n",
      "           6       0.84      0.74      0.79       235\n",
      "           7       0.09      0.20      0.12        85\n",
      "\n",
      "   micro avg       0.78      0.89      0.83      1325\n",
      "   macro avg       0.81      0.85      0.82      1325\n",
      "weighted avg       0.84      0.89      0.86      1325\n",
      " samples avg       0.86      0.92      0.86      1325\n",
      "\n",
      "Hamming Loss (Taux d'erreur par √©tiquette) : 5.99%\n",
      "(Exemple : 2% signifie que 98% des cases coch√©es/d√©coch√©es sont justes !)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Pr√©paration et Entra√Ænement Supervis√© ---\")\n",
    "\n",
    "# 1. Encodage des entr√©es (X)\n",
    "le_dept = LabelEncoder()\n",
    "users_df['dept_encoded'] = le_dept.fit_transform(users_df['department'])\n",
    "\n",
    "le_pos = LabelEncoder()\n",
    "users_df['pos_encoded'] = le_pos.fit_transform(users_df['position'])\n",
    "\n",
    "\n",
    "\n",
    "# L'IA doit juger uniquement sur le \"Qui je suis\" (Poste/Dept), pas le \"O√π je suis\".\n",
    "X_features = users_df[['dept_encoded', 'pos_encoded']] \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, Y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entra√Ænement...\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') # On garde balanced\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. √âvaluation rapide\n",
    "y_pred = clf.predict(X_test)\n",
    "# L'accuracy exacte est s√©v√®re (il faut avoir TOUT bon sur la ligne), donc on regarde un score moyen\n",
    "print(f\"Mod√®le entra√Æn√© sur {len(X_train)} utilisateurs.\")\n",
    "print(f\"Pr√©cision 'Subset' (Tout bon ou rien) : {accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(\"--- Rapport de Performance ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Hamming Loss (Taux d'erreur par √©tiquette) : {hamming_loss(y_test, y_pred):.2%}\")\n",
    "print(\"(Exemple : 2% signifie que 98% des cases coch√©es/d√©coch√©es sont justes !)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ec0fa0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MOTEUR DE RECOMMANDATION (IA + R√àGLES) ---\n",
      "Profil : DevOps / Department IT / Lyon\n",
      "----------------------------------------\n",
      " [IA] Analyse des besoins m√©tier (Seuil > 25.0%) :\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% de confiance -> [0] pack IT\n",
      "   [‚ñà‚ñà‚ñà‚ñà‚ñà     ] 58% de confiance -> [7] pack Collab\n",
      "\n",
      " [R√àGLES] Droits automatiques :\n",
      "    Badge Lyon\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tidianetall/Desktop/Desktop/Cours/PCE/Wavestone/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- D√âMO PROBABILISTE ---\n",
    "\n",
    "print(\"--- MOTEUR DE RECOMMANDATION (IA + R√àGLES) ---\")\n",
    "NEW_DEPT = \"Department IT\"\n",
    "NEW_POS  = \"DevOps\"\n",
    "NEW_LOC  = \"Lyon\"\n",
    "\n",
    "print(f\"Profil : {NEW_POS} / {NEW_DEPT} / {NEW_LOC}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ANALYSE (M√âTIER)\n",
    "# On abaisse le seuil de d√©cision pour √™tre pro-actif\n",
    "CONFIDENCE_THRESHOLD = 0.25  # Si l'IA est s√ªre √† 25%, on propose le r√¥le !\n",
    "\n",
    "try:\n",
    "    # On n'encode QUE Dept et Pos (On a retir√© la Loc de l'IA)\n",
    "    input_features = [[\n",
    "        le_dept.transform([NEW_DEPT])[0],\n",
    "        le_pos.transform([NEW_POS])[0]\n",
    "    ]]\n",
    "    \n",
    "    # Au lieu de predict(), on r√©cup√®re les probabilit√©s brutes\n",
    "    # Random Forest renvoie une liste de tableaux (un par r√¥le)\n",
    "    # C'est un peu technique, mais voici la formule magique :\n",
    "    probas = np.array(clf.predict_proba(input_features)) \n",
    "    # probas a la forme (n_roles, n_samples, 2_classes) -> On veut juste la proba du \"1\" (Oui)\n",
    "    scores_par_role = probas[:, 0, 1] \n",
    "    \n",
    "    found_roles = []\n",
    "    print(f\" [IA] Analyse des besoins m√©tier (Seuil > {CONFIDENCE_THRESHOLD*100}%) :\")\n",
    "    \n",
    "    # On parcourt tous les r√¥les et leur score\n",
    "    role_detected = False\n",
    "    for r_id, score in enumerate(scores_par_role):\n",
    "        if score >= CONFIDENCE_THRESHOLD:\n",
    "            role_detected = True\n",
    "            # On affiche une barre de confiance visuelle\n",
    "            bar = \"‚ñà\" * int(score * 10)\n",
    "            print(f\"   [{bar:<10}] {score:.0%} de confiance -> {describe_role(r_id)}\")\n",
    "            \n",
    "    if not role_detected:\n",
    "        print(\"   (Aucun signal m√©tier fort d√©tect√©)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur IA : {e}\")\n",
    "\n",
    "# 2. R√àGLES (LOGISTIQUE)\n",
    "print(f\"\\n [R√àGLES] Droits automatiques :\")\n",
    "if NEW_LOC == \"Lyon\":\n",
    "    print(\"    Badge Lyon\")\n",
    "    \n",
    "elif NEW_LOC == \"Paris\":\n",
    "    print(\"    Badge Paris\")\n",
    "\n",
    "print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
